{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0063b4",
   "metadata": {},
   "source": [
    "# Part 2: Fitting RL Models - Understanding Human Decision-Making\n",
    "\n",
    "## Introduction: Why Computational Modeling Matters\n",
    "\n",
    "In this tutorial, we will learn how to implement and evaluate computational models of human decision-making. This is a crucial skill for understanding how people learn, make choices, and adapt their behavior based on experience.\n",
    "\n",
    "### The Scientific Question\n",
    "\n",
    "Imagine you're a researcher studying how people learn to make optimal choices. You observe participants playing a simple game where they repeatedly choose between two slot machines with different (unknown) reward probabilities. Some participants learn quickly, others struggle. Some are cautious, others take risks. \n",
    "\n",
    "**The key question**: What cognitive strategies do people use to maximize their rewards? Are they using simple heuristics, sophisticated learning algorithms, or something in between?\n",
    "\n",
    "### The Wilson & Collins Framework\n",
    "\n",
    "This tutorial is based on the influential paper:\n",
    "**Wilson & Collins (2019) eLife: Ten simple rules for the computational modeling of behavioral data**\n",
    "\n",
    "The authors provide a systematic approach to computational modeling that involves:\n",
    "1. **Model Construction**: Building mathematical models of cognitive processes\n",
    "2. **Parameter Estimation**: Finding the best-fitting parameters for each individual\n",
    "3. **Model Comparison**: Determining which model best explains the data\n",
    "4. **Validation**: Ensuring our methods are reliable and meaningful\n",
    "\n",
    "### The 2-Armed Bandit Task\n",
    "\n",
    "We'll use a classic experimental paradigm: the 2-armed bandit task. In this task:\n",
    "- Participants perform $T$ choices between two options (slot machines)\n",
    "- The machines have asymmetric reward probabilities: $\\mu_{1} = 0.2$ and $\\mu_{2} = 0.8$\n",
    "- These probabilities are **unknown** to the participant\n",
    "- The goal is to maximize total reward over time\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "1. **Understand** three different models of human decision-making\n",
    "2. **Implement** behavioral analyses to compare model predictions\n",
    "3. **Validate** your modeling approach using parameter recovery\n",
    "4. **Evaluate** model identifiability using model recovery\n",
    "5. **Apply** these techniques to understand real human behavior\n",
    "\n",
    "### The Bigger Picture\n",
    "\n",
    "This tutorial demonstrates fundamental principles of computational cognitive science. These methods are used to:\n",
    "- Understand psychiatric conditions\n",
    "- Evaluate educational interventions\n",
    "- Design better human-computer interfaces\n",
    "- Study neural mechanisms of learning and decision-making\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6f921",
   "metadata": {},
   "source": [
    "## Setup: Importing Libraries and Data\n",
    "\n",
    "Let's start by importing the necessary modules and setting up our computational environment. We'll be working with numerical data, creating visualizations, and implementing optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcm\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Download the custom library - do this manually if not running on google colab\u001b[39;00m\n\u001b[1;32m      9\u001b[0m MODULE_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Download the custom library - do this manually if not running on google colab\n",
    "MODULE_NAME = \"models.py\"\n",
    "if not os.path.isfile(\"models.py\"):\n",
    "    MODULE_URL = f'https://raw.githubusercontent.com/bambschool/BAMB2025/main/Day_2_reinforcement_learning/part2_fitting_rl_models/{MODULE_NAME}'\n",
    "    !wget -O {MODULE_NAME} \"{MODULE_URL}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experimental Setup\n",
    "\n",
    "Before we dive into modeling, let's establish the experimental parameters that define our 2-armed bandit task. These parameters will be used throughout the tutorial to generate synthetic data and test our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy seed to 0 for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num_trials = 100\n",
    "reward_probabilities = np.array([0.2, 0.8])\n",
    "num_repetitions = 110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Three Models of Human Decision-Making\n",
    "\n",
    "Now we'll explore three different computational models that capture different theories about how humans make decisions in uncertain environments. Each model represents a different cognitive strategy that people might use when faced with the 2-armed bandit task.\n",
    "\n",
    "### Understanding the Models\n",
    "\n",
    "**Why three models?** Different people might use different strategies, and the same person might use different strategies in different contexts. By comparing multiple models, we can gain insights into the diversity of human decision-making processes.\n",
    "\n",
    "**Key insight**: These models make different predictions about behavior, which we can test against real data to understand which cognitive processes are most likely at play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Three Candidate Models\n",
    "\n",
    "We will consider three different computational models that represent distinct hypotheses about human decision-making:\n",
    "\n",
    "#### Model 1: **Noisy Win-Stay-Lose-Shift (WSLS)**\n",
    "- **Core idea**: Simple heuristic strategy\n",
    "- **Mechanism**: If the last choice was rewarded → repeat it; if not → switch to the other option\n",
    "- **Randomness**: Occasionally explores randomly (parameter: $\\epsilon$)\n",
    "- **Psychological insight**: Represents basic associative learning without sophisticated value computation\n",
    "- **Real-world example**: Like a person who sticks with a restaurant if they had a good meal, switches if they had a bad meal\n",
    "\n",
    "#### Model 2: **Rescorla-Wagner Learning**\n",
    "- **Core idea**: Sophisticated value learning based on prediction errors\n",
    "- **Mechanism**: Maintains estimates of each option's value, updates based on reward prediction error\n",
    "- **Parameters**: Learning rate $\\alpha_{RW}$ (how fast you learn) and softmax temperature $\\beta_{RW}$ (how deterministic your choices are)\n",
    "- **Psychological insight**: Represents gradual learning and memory integration\n",
    "- **Real-world example**: Like carefully tracking your experiences with different restaurants and slowly updating your preferences\n",
    "\n",
    "#### Model 3: **Choice Kernel**\n",
    "- **Core idea**: Tendency to repeat recent actions regardless of outcomes\n",
    "- **Mechanism**: Builds up \"momentum\" for recently chosen actions\n",
    "- **Parameters**: Kernel learning rate $\\alpha_{CK}$ and temperature $\\beta_{CK}$\n",
    "- **Psychological insight**: Captures perseveration and habit formation\n",
    "- **Real-world example**: Like having a favorite restaurant you keep going to out of habit, even when the food quality varies\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "These models make different predictions about:\n",
    "- **Sensitivity to rewards**: WSLS and Rescorla-Wagner are outcome-sensitive, Choice Kernel is not\n",
    "- **Learning speed**: Different models learn at different rates\n",
    "- **Exploration vs. exploitation**: Models balance these differently\n",
    "- **Individual differences**: People might use different strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Initialize the Models\n",
    "\n",
    "The models are already implemented in `models.py`. Let's import and initialize them. Take a moment to examine the code structure in `models.py` - notice how each model inherits from a base class and implements the same interface (simulate, fit, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WinStayLoseSwitch, RescorlaWagner, ChoiceKernel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize models\u001b[39;00m\n\u001b[1;32m      4\u001b[0m wsls_model \u001b[38;5;241m=\u001b[39m WinStayLoseSwitch()\n",
      "File \u001b[0;32m~/Documents/BAMB2025/Day_2_reinforcement_learning/part2_fitting_rl_models/models.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ABC, abstractmethod\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRLModel\u001b[39;00m(ABC):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "from models import WinStayLoseSwitch, RescorlaWagner, ChoiceKernel\n",
    "\n",
    "# Initialize models\n",
    "wsls_model = WinStayLoseSwitch()\n",
    "rw_model = RescorlaWagner()\n",
    "ck_model = ChoiceKernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. (Optional) Deep Dive: Implement Rescorla-Wagner Yourself\n",
    "\n",
    "**Learning objective**: Understand the mathematical details of the Rescorla-Wagner model by implementing it from scratch.\n",
    "\n",
    "While all models are provided in `models.py`, implementing the Rescorla-Wagner model yourself will deepen your understanding of how computational models work.\n",
    "\n",
    "**The Rescorla-Wagner learning rule**:\n",
    "- Start with initial value estimates: $Q_0 = [0.5, 0.5]$ (neutral expectations)\n",
    "- For each trial $t$:\n",
    "  1. **Choice**: Select action based on softmax: $P(a) = \\frac{e^{\\beta Q_a}}{\\sum_{a'} e^{\\beta Q_{a'}}}$\n",
    "  2. **Outcome**: Observe reward $r_t$ \n",
    "  3. **Learning**: Update value with prediction error: $Q_a \\leftarrow Q_a + \\alpha(r_t - Q_a)$\n",
    "\n",
    "**Key insights**:\n",
    "- $\\alpha$ controls learning speed (0 = no learning, 1 = only remember last outcome)\n",
    "- $\\beta$ controls choice determinism (0 = random, ∞ = always choose best)\n",
    "- The model learns from prediction errors, not just outcomes\n",
    "\n",
    "**Your task**: Fill in the methods below and compare with the implementation in `models.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf85424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import RLModel\n",
    "\n",
    "class RescorlaWagner(RLModel):\n",
    "    def simulate(self, T, mu, alpha, beta):\n",
    "        # initialize Q values, actions, rewards\n",
    "        Q = np.array([0.5, 0.5])\n",
    "        a, r = [], []\n",
    "\n",
    "        # for each timestep:\n",
    "        #   compute choice probability, action, reward\n",
    "        #   append action and reward to respective lists\n",
    "        #   update the Q value\n",
    "        # return the list of actions and rewards\n",
    "\n",
    "        return np.array(a), np.array(r)\n",
    "\n",
    "    def likelihood(self, pars, a, r):\n",
    "        alpha, beta = pars\n",
    "        Q = np.array([0.5, 0.5])\n",
    "        choice_p = []\n",
    "\n",
    "        # for each timestep:\n",
    "        #   compute action probability\n",
    "        #   append it to the choice_p list\n",
    "        #   update the Q value\n",
    "        # return the negative log likelihood\n",
    "\n",
    "    def initial_parameters(self):\n",
    "        return [np.random.random(), np.random.exponential()]\n",
    "\n",
    "    def parameter_bounds(self):\n",
    "        return [(0, 1), (0, np.inf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Simulate the Models\n",
    "\n",
    "**Learning objective**: Generate synthetic behavioral data from our three models to understand their predictions.\n",
    "\n",
    "**Why simulate?** Before we can fit models to real data, we need to understand what behavior each model predicts. Simulation allows us to:\n",
    "- Test our implementation\n",
    "- Understand parameter effects\n",
    "- Generate ground truth data for validation\n",
    "- Explore the model's behavioral repertoire\n",
    "\n",
    "**Your task**: Implement the `simulate_model()` function that will generate synthetic choice sequences for each model. The function should:\n",
    "- Take a model instance and parameters\n",
    "- Run multiple simulations (repetitions)\n",
    "- Return lists of actions and rewards for analysis\n",
    "\n",
    "**Parameter choices**: We'll use these parameters for our simulations:\n",
    "- **Win Stay Lose Shift**: $\\epsilon=0.1$ (10% random exploration)\n",
    "- **Rescorla Wagner**: $\\alpha_{RW}=0.1$ (slow learning), $\\beta_{RW}=3$ (moderately deterministic)\n",
    "- **Choice Kernel**: $\\alpha_{CK}=0.1$ (slow habit formation), $\\beta_{CK}=3$ (moderately deterministic)\n",
    "\n",
    "**Think about**: How do you expect these different models to behave? Which should perform best? Which should be most/least sensitive to rewards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wsls_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m     actions, rewards \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# for each repitition\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#   simiulate models\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#   append actions and rewards to the respective lists\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# return actions, rewards\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Simulate models\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m a_wsls, r_wsls \u001b[38;5;241m=\u001b[39m simulate_model(\u001b[43mwsls_model\u001b[49m, num_repetitions, num_trials, reward_probabilities, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     11\u001b[0m a_rw, r_rw \u001b[38;5;241m=\u001b[39m simulate_model(rw_model, num_repetitions, num_trials, reward_probabilities, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     12\u001b[0m a_ck, r_ck \u001b[38;5;241m=\u001b[39m simulate_model(ck_model, num_repetitions, num_trials, reward_probabilities, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wsls_model' is not defined"
     ]
    }
   ],
   "source": [
    "# define a function to simulate the models and collect data\n",
    "def simulate_model(model, num_reps, num_trials, reward_probs, **params):\n",
    "    actions, rewards = [], []\n",
    "    # for each repitition\n",
    "    #   simiulate models\n",
    "    #   append actions and rewards to the respective lists\n",
    "    # return actions, rewards\n",
    "\n",
    "# Simulate models\n",
    "a_wsls, r_wsls = simulate_model(wsls_model, num_repetitions, num_trials, reward_probabilities, epsilon=0.1)\n",
    "a_rw, r_rw = simulate_model(rw_model, num_repetitions, num_trials, reward_probabilities, alpha=0.1, beta=5)\n",
    "a_ck, r_ck = simulate_model(ck_model, num_repetitions, num_trials, reward_probabilities, alpha=0.1, beta=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each model, you should also play with the parameters used to generate the simulations and observe the effect on Win-Stay-Lose-Shift analysis (see below). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Behavioral Analysis: Understanding Model Predictions\n",
    "\n",
    "**Learning objective**: Learn to analyze and visualize model behavior to understand what makes different models distinct.\n",
    "\n",
    "**Why behavioral analysis?** Before fitting models to real data, we need to understand what patterns each model predicts. This helps us:\n",
    "- Identify which models are actually different from each other\n",
    "- Understand what behavioral signatures to look for in real data\n",
    "- Design better experiments that can distinguish between models\n",
    "- Build intuition about model behavior\n",
    "\n",
    "**The key insight**: If two models predict identical behavior, there's no point in comparing them. Good computational modeling requires models that make different, testable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Win-Stay-Lose-Shift Analysis\n",
    "\n",
    "**What is WSLS analysis?** Win-Stay-Lose-Shift analysis is a fundamental tool in behavioral neuroscience that measures how much a decision-maker's choices depend on the outcomes of their previous actions.\n",
    "\n",
    "**Why is this useful?** WSLS analysis reveals:\n",
    "- **Outcome sensitivity**: How much do previous rewards influence future choices?\n",
    "- **Model differences**: Different models show distinct WSLS patterns\n",
    "- **Individual differences**: People vary in their WSLS behavior\n",
    "- **Clinical applications**: WSLS patterns change in psychiatric conditions\n",
    "\n",
    "**The measurement**: We calculate:\n",
    "- $p(stay|win)$: Probability of repeating an action after it was rewarded\n",
    "- $p(stay|lose)$: Probability of repeating an action after it was unrewarded\n",
    "\n",
    "**Expected patterns**:\n",
    "- **WSLS model**: Should show stark differences (high p(stay|win), low p(stay|lose))\n",
    "- **Rescorla-Wagner**: Should show moderate outcome sensitivity\n",
    "- **Choice Kernel**: Should show similar p(stay) regardless of previous reward\n",
    "\n",
    "This analysis reproduces **Figure 1** from Wilson & Collins (2019), demonstrating how different models produce distinct behavioral signatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Compare qualitative patterns from our three different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Implementing WSLS Analysis\n",
    "\n",
    "**Your task**: Implement the `compute_stay_probabilities()` function that calculates WSLS measures from behavioral data.\n",
    "\n",
    "**Algorithm**:\n",
    "1. For each trial $t > 1$:\n",
    "   - Determine if the participant \"stayed\" (chose the same action as trial $t-1$)\n",
    "   - Check if the previous trial was rewarded or unrewarded\n",
    "2. Calculate:\n",
    "   - $p(stay|win) = \\frac{\\text{number of stays after wins}}{\\text{total number of wins}}$\n",
    "   - $p(stay|lose) = \\frac{\\text{number of stays after losses}}{\\text{total number of losses}}$\n",
    "\n",
    "**Implementation hints**:\n",
    "- Use `np.hstack()` to handle the first trial (which has no previous trial)\n",
    "- Be careful with indexing - you're comparing trial $t$ with trial $t-1$\n",
    "- Use `np.nanmean()` to handle missing values appropriately\n",
    "\n",
    "**What to expect**: After implementing this function, you should be able to reproduce the characteristic WSLS patterns that distinguish the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stay_probabilities(actions, rewards):\n",
    "    \"\"\"Compute probability of stay given win/lose.\"\"\"\n",
    "    # return lose_stay, win_stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate WSLS for each model\n",
    "model_actions = [a_wsls, a_rw, a_ck]\n",
    "model_rewards = [r_wsls, r_rw, r_ck]\n",
    "model_names = ['WSLS', 'Rescorla-Wagner', 'Choice kernel']\n",
    "\n",
    "wsls_probs = []\n",
    "for actions, rewards in zip(model_actions, model_rewards):\n",
    "    wsls_probs.append(np.mean([compute_stay_probabilities(actions[n], rewards[n]) for n in range(num_repetitions)], axis=0))\n",
    "\n",
    "# Loop over your models\n",
    "A = [a_wsls, a_rw, a_ck]\n",
    "R = [r_wsls, r_rw, r_ck]\n",
    "\n",
    "wsls_probs = []\n",
    "for actions, rewards in zip(model_actions, model_rewards):\n",
    "    wsls_probs.append(np.mean([compute_stay_probabilities(actions[n], rewards[n]) for n in range(num_repetitions)], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot WSLS behavior as a function of previous reward (1 for rewarded, 0 for unrewarded)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does each model modulate its probability of staying as a function of previous reward? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot WSLS as a function of previous reward\n",
    "plt.figure(figsize=(4, 4), dpi=100)\n",
    "for i, prob in enumerate(wsls_probs):\n",
    "    plt.plot([0, 1], prob, 'o-', label=model_names[i])\n",
    "plt.xlabel('Previous reward')\n",
    "plt.ylabel('Probability of staying')\n",
    "plt.xticks([0, 1])\n",
    "plt.legend(frameon=False)\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the choice kernel model leads to a reward-independent $p(stay)$, because choice probabilities are calculated independently of the previous reward. All other models show outcome-modulated behavior, with the starkest differences for the WSLS simulation.\n",
    "\n",
    "*Take home message*: More broadly, these patterns of behavior can then be contrasted again actual behavioral data to inform about subjects' behavior. It is important to simulate your candidate models and plot their behavior before comparing them to actual data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Parameter Effects Analysis: Understanding the Rescorla-Wagner Model\n",
    "\n",
    "**Learning objective**: Understand how model parameters affect behavior and performance.\n",
    "\n",
    "**Why study parameter effects?** Different parameter values lead to different behavioral patterns. Understanding these relationships helps us:\n",
    "- Interpret fitted parameters meaningfully\n",
    "- Design better experiments\n",
    "- Understand individual differences\n",
    "- Predict the effects of interventions\n",
    "\n",
    "**The analysis**: We'll systematically vary the Rescorla-Wagner parameters ($\\alpha$ and $\\beta$) and measure how they affect performance in early vs. late trials.\n",
    "\n",
    "**Key questions**:\n",
    "- How does learning rate ($\\alpha$) affect early learning vs. asymptotic performance?\n",
    "- How does temperature ($\\beta$) interact with learning rate?\n",
    "- Are there optimal parameter combinations?\n",
    "- What do these patterns tell us about the explore-exploit tradeoff?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Rescorla Wagner, we are now interested in how learning rate and softmax inverse temperate affect the probability of choosing the arm with the highest reward. \n",
    "\n",
    "We will repeatedly perform a grid search over different parameter values (~ 1000 simulations with 100 trials per grid point) and store the mean $p(correct)$ across trials for each grid point and repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid search for Rescorla-Wagner model\n",
    "alphas = np.linspace(0.02, 1, 4)\n",
    "betas = np.array([1, 2, 5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first use only 10 simulations for each parameter combination. When your code works, increase to 1000.\n",
    "num_reps = 1_000\n",
    "\n",
    "# Initialize arrays to collect data\n",
    "correct = np.zeros((len(alphas), len(betas), num_reps))\n",
    "correct_early = np.zeros((len(alphas), len(betas), num_reps))\n",
    "correct_late = np.zeros((len(alphas), len(betas), num_reps))\n",
    "\n",
    "# Evaluation loop: grid-search over alpha and beta parameters for a large number of simulations\n",
    "# on which you will then average.\n",
    "    # simulate rescorla wagner model and collect sequence of actions and rewards\n",
    "    # collect the performance\n",
    "    # store performance for early (first 10 trials) and late (last 10 trials of a block) trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot $p(correct)$ as a function of $\\alpha$ and $\\beta$. Create the figure with two subplots: one for early, one for late trials.\n",
    "\n",
    "As in Wilson & Collins box 2 figure 1, plot different levels of $\\alpha$ on the x-axis and use different curves for $\\beta$ levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your figure with two subplots here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does performance change as a function of alpha and beta parameter values, for early and late trials?\n",
    "\n",
    "The left graph shows that the learning rate is positively correlated with increases in early performance only for low $\\beta$ values, or very low $\\alpha$ values. For high $\\beta$ values, there is a U-shaped relationship between learning rate and early speed of learning. The right graph shows that with high $\\beta$ values, high learning rates negatively influence asymptotic behavior. Thus, both parameters interact to influence both the speed of learning and asymptotic performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusion*: This kind of analysis will allow you to see qualitative differences between models, so that making their predictions in the experimental setup different. If the behavior of different models is not qualitatively different, this is a sign that you should try to design a better experiment. While not always possible, distinguishing between models on the basis of qualitative patterns in the data is preferable to quantitative model comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parameter Recovery: Validating Our Methods\n",
    "\n",
    "**Learning objective**: Learn to validate computational modeling methods using parameter recovery.\n",
    "\n",
    "**What is parameter recovery?** Parameter recovery tests whether our fitting procedure can accurately recover the true parameters used to generate synthetic data. This is crucial because:\n",
    "- It validates that our fitting method works correctly\n",
    "- It reveals parameter ranges where fitting is reliable\n",
    "- It identifies potential biases in our estimation procedure\n",
    "- It's required before applying methods to real data\n",
    "\n",
    "**The logic**:\n",
    "1. **Generate**: Use known parameters to simulate behavioral data\n",
    "2. **Fit**: Apply our fitting procedure to recover the parameters\n",
    "3. **Compare**: Check how well recovered parameters match the true parameters\n",
    "\n",
    "**Why this matters**: If we can't recover known parameters from synthetic data, we can't trust our method when applied to real data where the true parameters are unknown.\n",
    "\n",
    "**Wilson & Collins Rule #8**: \"Parameter recovery is essential for validating your computational modeling approach.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Simulation and fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Parameter Recovery Procedure\n",
    "\n",
    "**The systematic approach**:\n",
    "1. **Sample parameters**: Draw random parameter values from realistic distributions\n",
    "2. **Simulate behavior**: Generate synthetic data using these parameters\n",
    "3. **Fit model**: Apply maximum likelihood estimation to recover parameters\n",
    "4. **Evaluate**: Compare recovered vs. true parameters\n",
    "\n",
    "**What to look for**:\n",
    "- **Correlation**: Strong correlation between true and recovered parameters\n",
    "- **Bias**: Systematic over- or under-estimation\n",
    "- **Range effects**: Whether recovery quality depends on parameter values\n",
    "- **Noise**: How much variability there is in recovery\n",
    "\n",
    "**Implementation strategy**: We'll focus on the Rescorla-Wagner model, using realistic parameter ranges and sufficient trial numbers to ensure reliable fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do this step by step. We will first simulate actions of the model for a given learning rate, $\\alpha$, and softmax parameter, $\\beta$.\t\t\t\n",
    "\n",
    "After simulating the model, we will fit the parameters using a maximum likelihood approach to get estimated values $\\hat{\\alpha}$ and $\\hat{\\beta}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "num_reps = 100\n",
    "alphas = np.random.rand(num_reps)\n",
    "betas = 10 * np.random.exponential(size=num_reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the simulated data. \n",
    "\n",
    "Fit Rescorla Wagner by calling the `fit()` method for that model, `rw_model.fit()`, which takes as inputs actions and rewards. We will not focus on the goodness of fit here, but you should take a moment to look at the specification in `.fit()` and `likelihood()` methods of the model in `models.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample random parameters\n",
    "\n",
    "# loop over repetitions \n",
    "\n",
    "    # set different fixed seeds per repetition\n",
    "    \n",
    "    # simulate M3\n",
    "\n",
    "    # fit and store parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Parameter recovery plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to visualise the fitted parameter values as a function of the generating parameter values. We will have one data point for each iteration. Here, you should use the generating values and the fitted values that you have stored in the section above. You should create two subplots, one for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your figure with two subplots goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you observe a fairly good agreement between the simulated and fit parameter values?\n",
    "\n",
    "The plot makes any correlations clear, and also reveals whether the correlation holds in some parameter regimes but not others. It also reveals any existing bias (e.g. a tendency to recover higher or lower values in average).\n",
    "\n",
    "Here we can see that the fit for $\\beta$ is best with a range, $0.1 < \\beta < 10$ and that outside this range, the correspondence between simulation and fit is not as good.\n",
    "\n",
    "Depending on the values of $\\beta$ that we obtain when fitting human behavior, this worse correspondence at small and large $\\beta$ may or may not be problematic. It may be a good idea to use the range of parameters obtained from fitting the real data to test the quality of recovery within the range that matters. \n",
    "\n",
    "Reliable parameter recovery is particularly important for look at inter-individual differences in relation to questionnaire scores or brain data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Recovery: Testing Model Identifiability\n",
    "\n",
    "**Learning objective**: Learn to test whether different models can be reliably distinguished from each other.\n",
    "\n",
    "**What is model recovery?** Model recovery (also called model identifiability) tests whether we can correctly identify which model generated a given dataset. This is essential because:\n",
    "- It validates that our models are actually different from each other\n",
    "- It reveals when models are confusable\n",
    "- It helps design better experiments\n",
    "- It's required before making claims about which model best fits real data\n",
    "\n",
    "**The confusion matrix approach**:\n",
    "1. **Simulate**: Generate data from each model using realistic parameters\n",
    "2. **Fit all models**: Apply all models to each simulated dataset\n",
    "3. **Select best**: Choose the model with the best fit (lowest BIC)\n",
    "4. **Tabulate**: Create a confusion matrix showing recovery rates\n",
    "\n",
    "**Reading the confusion matrix**:\n",
    "- **Rows**: True generating model\n",
    "- **Columns**: Best-fitting model\n",
    "- **Diagonal**: Correct model identification\n",
    "- **Off-diagonal**: Model confusability\n",
    "\n",
    "**Wilson & Collins Rule #9**: \"Test model recovery to ensure your models are distinguishable.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate model recovery, here we will simulate behavior of our three models on the two-armed bandits task. \n",
    "\n",
    "As before, the means $\\mu$ can be set at 0.2 and 0.8, and the number of trials at $T = 1000$. For each simulation, model parameters can be sampled randomly for each model. \n",
    "\n",
    "Each simulated data set will then be fit to each of the given models, to determine which model fit best (according to BIC). This process will be repeated 100 times (number of \"repetitions\" or \"counts\") to compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "num_trials = 1_000\n",
    "num_counts = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Building the Confusion Matrix\n",
    "\n",
    "**Implementation approach**:\n",
    "1. **For each repetition**:\n",
    "   - For each of the 3 models, generate synthetic data with random parameters\n",
    "   - Fit all 3 models to each dataset\n",
    "   - Record which model fits best (lowest BIC)\n",
    "2. **Tabulate results**: Count how often each model is correctly identified\n",
    "\n",
    "**What makes a good confusion matrix?**\n",
    "- **Strong diagonal**: High values on the diagonal indicate good model recovery\n",
    "- **Weak off-diagonal**: Low values off the diagonal indicate models are distinguishable\n",
    "- **Balanced**: All models should be recoverable, not just one\n",
    "\n",
    "**Parameter considerations**: The confusion matrix depends heavily on the parameter ranges used for simulation. Parameters should match those observed in real human data when possible.\n",
    "\n",
    "**Troubleshooting**: If you get poor model recovery, consider:\n",
    "- Increasing the number of trials\n",
    "- Adjusting parameter ranges\n",
    "- Using different model comparison criteria\n",
    "- Checking if models are actually different enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# models to loop through\n",
    "models = [wsls_model, rw_model, ck_model]\n",
    "\n",
    "# initialise your confusion matrix: 3 by 3 (for our three models).\n",
    "confusion_matrix = np.zeros((3, 3))\n",
    "\n",
    "# Let's loop over number of repetitions: start with 10, increase to 100 if everything works\n",
    "\n",
    "    # set different fixed seed for each repetition\n",
    "\n",
    "    # for each model\n",
    "    #   simulate to get actions and rewards\n",
    "\n",
    "    # fit models\n",
    "    # compute best model and confusion matrix    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and print values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Interpreting Model Recovery Results\n",
    "\n",
    "**Understanding the confusion matrix**:\n",
    "- **Perfect recovery**: Identity matrix (1s on diagonal, 0s elsewhere)\n",
    "- **Poor recovery**: Uniform matrix (all values around 0.33)\n",
    "- **Systematic bias**: Consistent mis-identification patterns\n",
    "\n",
    "**Critical questions to consider**:\n",
    "- Are all models recoverable with reasonable accuracy (>70% on diagonal)?\n",
    "- Are there systematic confusions between specific model pairs?\n",
    "- How does changing parameters affect model recovery?\n",
    "- Are the parameter ranges realistic for human behavior?\n",
    "\n",
    "**Real-world implications**:\n",
    "- **Good recovery**: You can trust model comparison results on real data\n",
    "- **Poor recovery**: Models may be too similar or experiment too short\n",
    "- **Parameter-dependent recovery**: Need to match simulation parameters to real data\n",
    "\n",
    "**Wilson & Collins insight**: \"Models that are identifiable in one parameter regime may be impossible to distinguish in another regime.\"\n",
    "\n",
    "**Final considerations**:\n",
    "- Model recovery is just one validation step - you should also check parameter recovery\n",
    "- The confusion matrix only tells you about the models you tested - there may be other models that fit better\n",
    "- Always start with good models that capture competing scientific hypotheses\n",
    "- Consider both qualitative (behavioral patterns) and quantitative (model comparison) approaches\n",
    "\n",
    "**Congratulations!** You've now completed a full computational modeling workflow following the Wilson & Collins framework. You're ready to apply these methods to real behavioral data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
